---

title: Run Bert Multitask Learning


keywords: fastai
sidebar: home_sidebar



nb_path: "source_nbs/14_run_bert_multitask.ipynb"
---
<!--

#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: source_nbs/14_run_bert_multitask.ipynb
# command to build the docs after a change: nbdev_build_docs

-->

<div class="container" id="notebook-container">
        
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Imports">Imports<a class="anchor-link" href="#Imports"> </a></h2>
</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Test-setup">Test setup<a class="anchor-link" href="#Test-setup"> </a></h2>
</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="create_keras_model" class="doc_header"><code>create_keras_model</code><a href="https://github.com/JayYip/m3tl/tree/master/m3tl/run_bert_multitask.py#L34" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>create_keras_model</code>(<strong><code>mirrored_strategy</code></strong>:<code>MirroredStrategy</code>, <strong><code>params</code></strong>:<a href="/m3tl/1_params.html#Params"><code>Params</code></a>, <strong><code>mode</code></strong>=<em><code>'train'</code></em>, <strong><code>inputs_to_build_model</code></strong>=<em><code>None</code></em>, <strong><code>model</code></strong>=<em><code>None</code></em>, <strong><code>run_eagerly</code></strong>=<em><code>False</code></em>)</p>
</blockquote>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Init model in various mode</p>
<p><code>train</code>: model will be loaded from huggingface
<code>resume</code>: model will be loaded from params.ckpt_dir, if params.ckpt_dir dose not contain valid checkpoint, then load from huggingface
<code>transfer</code>: model will be loaded from params.init_checkpoint, the correspongding path should contain checkpoints saved using m3tl
<code>predict</code>: model will be loaded from params.ckpt_dir except optimizers' states
<code>eval</code>: model will be loaded from params.ckpt_dir except optimizers' states, model will be compiled</p>
<p>Args:</p>
<ul>
<li>mirrored_strategy (tf.distribute.MirroredStrategy): mirrored strategy</li>
<li>params (Params): params</li>
<li>mode (str, optional): Mode, see above explaination. Defaults to 'train'.</li>
<li>inputs_to_build_model (Dict, optional): A batch of data. Defaults to None.</li>
<li>model (Model, optional): Keras model. Defaults to None.</li>
</ul>
<p>Returns:</p>
<ul>
<li>model: loaded model</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Train-model">Train model<a class="anchor-link" href="#Train-model"> </a></h2>
</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="get_params_ready" class="doc_header"><code>get_params_ready</code><a href="https://github.com/JayYip/m3tl/tree/master/m3tl/run_bert_multitask.py#L179" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>get_params_ready</code>(<strong><code>problem</code></strong>, <strong><code>num_gpus</code></strong>, <strong><code>model_dir</code></strong>, <strong><code>params</code></strong>, <strong><code>problem_type_dict</code></strong>, <strong><code>processing_fn_dict</code></strong>, <strong><code>mode</code></strong>=<em><code>'train'</code></em>, <strong><code>json_path</code></strong>=<em><code>''</code></em>)</p>
</blockquote>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="train_bert_multitask" class="doc_header"><code>train_bert_multitask</code><a href="https://github.com/JayYip/m3tl/tree/master/m3tl/run_bert_multitask.py#L210" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>train_bert_multitask</code>(<strong><code>problem</code></strong>=<em><code>'weibo_ner'</code></em>, <strong><code>num_gpus</code></strong>=<em><code>1</code></em>, <strong><code>num_epochs</code></strong>=<em><code>10</code></em>, <strong><code>model_dir</code></strong>=<em><code>''</code></em>, <strong><code>params</code></strong>:<a href="/m3tl/1_params.html#Params"><code>Params</code></a>=<em><code>None</code></em>, <strong><code>problem_type_dict</code></strong>:<code>Dict</code>[<code>str</code>, <code>str</code>]=<em><code>None</code></em>, <strong><code>processing_fn_dict</code></strong>:<code>Dict</code>[<code>str</code>, <code>Callable</code>]=<em><code>None</code></em>, <strong><code>model</code></strong>:<code>Model</code>=<em><code>None</code></em>, <strong><code>create_tf_record_only</code></strong>=<em><code>False</code></em>, <strong><code>steps_per_epoch</code></strong>:<code>int</code>=<em><code>None</code></em>, <strong><code>warmup_ratio</code></strong>=<em><code>0.1</code></em>, <strong><code>continue_training</code></strong>=<em><code>False</code></em>, <strong><code>mirrored_strategy</code></strong>:<code>MirroredStrategy</code>=<em><code>None</code></em>, <strong><code>run_eagerly</code></strong>=<em><code>False</code></em>, <strong><code>callbacks</code></strong>:<code>List</code>[<code>Callback</code>]=<em><code>None</code></em>, <strong><code>verbose</code></strong>=<em><code>1</code></em>)</p>
</blockquote>
<p>Train Multi-task Bert model</p>
<p>Keyword Arguments:</p>
<ul>
<li>problem (str, optional) -- Problems to train. Defaults to 'weibo_ner'</li>
<li>num_gpus (int, optional) -- Number of GPU to use. Defaults to 1</li>
<li>num_epochs (int, optional) -- Number of epochs to train. Defaults to 10</li>
<li>model_dir (str, optional) -- model dir. Defaults to ''</li>
<li>params (Params, optional) -- Params to define training and models. Defaults to None</li>
<li>problem_type_dict (dict, optional) -- Key: problem name, value: problem type. Defaults to None</li>
<li>processing_fn_dict (dict, optional) -- Key: problem name, value: problem data preprocessing fn. Defaults to None</li>
<li>model (tf.keras.Model, optional): if not provided, it will be created using <a href="/m3tl/run_bert_multitask.html#create_keras_model"><code>create_keras_model</code></a>. Defaults to None.</li>
<li>create_tf_record_only (bool, optional): if <code>True</code>, the function will only create TFRecord without training model. Defaults to False.</li>
<li>steps_per_epoch (int, optional): steps per epochs, if not provided, train datset will be looped once to calculate steps per epoch. Defaults to None.</li>
<li>warmup_ratio (float, optional): lr warmup ratio. Defaults to 0.1.</li>
<li>continue_training (bool, optional): whether to resume training from <code>model_dir</code>. Defaults to False.</li>
<li>mirrored_strategy (MirroredStrategy, optional): Tensorflow MirroredStrategy. Defaults to None.</li>
<li>run_eagerly (bool, optional): Whether to run model eagerly. Defaults to False.</li>
<li>callbacks (list, optional): list of callbacks to add during training. If None, ModelCheckpoint will be added.</li>
<li>verbose (int, optional): 0, 1, or 2. Verbosity mode. 0 = silent, 1 = progress bar, 2 = one line per epoch. Note that the progress bar is not particularly useful when logged to a file, so verbose=2 is recommended when not running interactively (eg, in a production environment).</li>
</ul>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Train Multi-task Bert model</p>
<p>Keyword Arguments:</p>
<ul>
<li>problem (str, optional) -- Problems to train. Defaults to 'weibo_ner'</li>
<li>num_gpus (int, optional) -- Number of GPU to use. Defaults to 1</li>
<li>num_epochs (int, optional) -- Number of epochs to train. Defaults to 10</li>
<li>model_dir (str, optional) -- model dir. Defaults to ''</li>
<li>params (Params, optional) -- Params to define training and models. Defaults to None</li>
<li>problem_type_dict (dict, optional) -- Key: problem name, value: problem type. Defaults to None</li>
<li>processing_fn_dict (dict, optional) -- Key: problem name, value: problem data preprocessing fn. Defaults to None</li>
<li>model (tf.keras.Model, optional): if not provided, it will be created using <a href="/m3tl/run_bert_multitask.html#create_keras_model"><code>create_keras_model</code></a>. Defaults to None.</li>
<li>create_tf_record_only (bool, optional): if <code>True</code>, the function will only create TFRecord without training model. Defaults to False.</li>
<li>steps_per_epoch (int, optional): steps per epochs, if not provided, train datset will be looped once to calculate steps per epoch. Defaults to None.</li>
<li>warmup_ratio (float, optional): lr warmup ratio. Defaults to 0.1.</li>
<li>continue_training (bool, optional): whether to resume training from <code>model_dir</code>. Defaults to False.</li>
<li>mirrored_strategy (MirroredStrategy, optional): Tensorflow MirroredStrategy. Defaults to None.</li>
<li>run_eagerly (bool, optional): Whether to run model eagerly. Defaults to False.</li>
</ul>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">params</span><span class="o">.</span><span class="n">use_horovod</span> <span class="o">=</span> <span class="kc">False</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">train_bert_multitask</span><span class="p">(</span>
    <span class="n">problem</span><span class="o">=</span><span class="n">problem</span><span class="p">,</span>
    <span class="n">num_epochs</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">params</span><span class="o">=</span><span class="n">params</span><span class="p">,</span>
    <span class="n">problem_type_dict</span><span class="o">=</span><span class="n">problem_type_dict</span><span class="p">,</span>
    <span class="n">processing_fn_dict</span><span class="o">=</span><span class="n">processing_fn_dict</span><span class="p">,</span>
    <span class="n">steps_per_epoch</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">continue_training</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">mirrored_strategy</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="n">run_eagerly</span><span class="o">=</span><span class="kc">True</span>
<span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>2021-06-17 13:22:41.927 | INFO     | m3tl.base_params:register_multiple_problems:538 - Adding new problem weibo_fake_ner, problem type: seq_tag
2021-06-17 13:22:41.928 | INFO     | m3tl.base_params:register_multiple_problems:538 - Adding new problem weibo_cws, problem type: seq_tag
2021-06-17 13:22:41.928 | INFO     | m3tl.base_params:register_multiple_problems:538 - Adding new problem weibo_fake_multi_cls, problem type: multi_cls
2021-06-17 13:22:41.929 | INFO     | m3tl.base_params:register_multiple_problems:538 - Adding new problem weibo_fake_cls, problem type: cls
2021-06-17 13:22:41.929 | INFO     | m3tl.base_params:register_multiple_problems:538 - Adding new problem weibo_masklm, problem type: masklm
2021-06-17 13:22:41.930 | INFO     | m3tl.base_params:register_multiple_problems:538 - Adding new problem weibo_pretrain, problem type: pretrain
2021-06-17 13:22:41.930 | INFO     | m3tl.base_params:register_multiple_problems:538 - Adding new problem weibo_premask_mlm, problem type: premask_mlm
2021-06-17 13:22:41.931 | WARNING  | m3tl.base_params:prepare_dir:361 - bert_config not exists. will load model from huggingface checkpoint.
2021-06-17 13:22:42.005 | WARNING  | m3tl.read_write_tfrecord:chain_processed_data:250 - Chaining problems with &amp; may consume a lot of memory if data is not pyspark RDD.
2021-06-17 13:22:42.012 | DEBUG    | m3tl.read_write_tfrecord:_write_fn:134 - Writing /tmp/tmp4ngci4nl/weibo_fake_cls_weibo_fake_ner/train_00000.tfrecord
2021-06-17 13:22:42.043 | WARNING  | m3tl.read_write_tfrecord:chain_processed_data:250 - Chaining problems with &amp; may consume a lot of memory if data is not pyspark RDD.
2021-06-17 13:22:42.050 | DEBUG    | m3tl.read_write_tfrecord:_write_fn:134 - Writing /tmp/tmp4ngci4nl/weibo_fake_cls_weibo_fake_ner/eval_00000.tfrecord
2021-06-17 13:22:42.075 | DEBUG    | m3tl.read_write_tfrecord:_write_fn:134 - Writing /tmp/tmp4ngci4nl/weibo_fake_multi_cls/train_00000.tfrecord
2021-06-17 13:22:42.101 | DEBUG    | m3tl.read_write_tfrecord:_write_fn:134 - Writing /tmp/tmp4ngci4nl/weibo_fake_multi_cls/eval_00000.tfrecord
2021-06-17 13:22:42.176 | DEBUG    | m3tl.read_write_tfrecord:_write_fn:134 - Writing /tmp/tmp4ngci4nl/weibo_masklm/train_00000.tfrecord
2021-06-17 13:22:42.224 | DEBUG    | m3tl.read_write_tfrecord:_write_fn:134 - Writing /tmp/tmp4ngci4nl/weibo_masklm/eval_00000.tfrecord
2021-06-17 13:22:42.288 | DEBUG    | m3tl.read_write_tfrecord:_write_fn:134 - Writing /tmp/tmp4ngci4nl/weibo_premask_mlm/train_00000.tfrecord
2021-06-17 13:22:42.352 | DEBUG    | m3tl.read_write_tfrecord:_write_fn:134 - Writing /tmp/tmp4ngci4nl/weibo_premask_mlm/eval_00000.tfrecord
2021-06-17 13:22:43.501 | INFO     | m3tl.input_fn:train_eval_input_fn:59 - sampling weights: 
2021-06-17 13:22:43.501 | INFO     | m3tl.input_fn:train_eval_input_fn:60 - {
    &#34;weibo_fake_cls_weibo_fake_ner&#34;: 0.2702702702702703,
    &#34;weibo_fake_multi_cls&#34;: 0.2702702702702703,
    &#34;weibo_masklm&#34;: 0.1891891891891892,
    &#34;weibo_premask_mlm&#34;: 0.2702702702702703
}
2021-06-17 13:22:44.126 | INFO     | m3tl.input_fn:train_eval_input_fn:59 - sampling weights: 
2021-06-17 13:22:44.127 | INFO     | m3tl.input_fn:train_eval_input_fn:60 - {
    &#34;weibo_fake_cls_weibo_fake_ner&#34;: 0.2702702702702703,
    &#34;weibo_fake_multi_cls&#34;: 0.2702702702702703,
    &#34;weibo_masklm&#34;: 0.1891891891891892,
    &#34;weibo_premask_mlm&#34;: 0.2702702702702703
}
2021-06-17 13:22:44.190 | CRITICAL | m3tl.base_params:update_train_steps:454 - Updating train_steps to 1
2021-06-17 13:22:44.874 | INFO     | m3tl.input_fn:train_eval_input_fn:59 - sampling weights: 
2021-06-17 13:22:44.875 | INFO     | m3tl.input_fn:train_eval_input_fn:60 - {
    &#34;weibo_fake_cls_weibo_fake_ner&#34;: 0.2702702702702703,
    &#34;weibo_fake_multi_cls&#34;: 0.2702702702702703,
    &#34;weibo_masklm&#34;: 0.1891891891891892,
    &#34;weibo_premask_mlm&#34;: 0.2702702702702703
}
404 Client Error: Not Found for url: https://huggingface.co/voidful/albert_chinese_tiny/resolve/main/tf_model.h5
Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFAlbertModel: [&#39;predictions.dense.bias&#39;, &#39;predictions.decoder.weight&#39;, &#39;predictions.LayerNorm.weight&#39;, &#39;predictions.bias&#39;, &#39;predictions.dense.weight&#39;, &#39;predictions.LayerNorm.bias&#39;, &#39;predictions.decoder.bias&#39;]
- This IS expected if you are initializing TFAlbertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing TFAlbertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).
All the weights of TFAlbertModel were initialized from the PyTorch model.
If your task is similar to the task the model of the checkpoint was trained on, you can already use TFAlbertModel for predictions without further training.
2021-06-17 13:22:49.859 | CRITICAL | m3tl.embedding_layer.base:__init__:58 - Modal Type id mapping: 
 {
    &#34;array&#34;: 0,
    &#34;cate&#34;: 1,
    &#34;text&#34;: 2
}
2021-06-17 13:22:49.951 | WARNING  | m3tl.problem_types.masklm:__init__:41 - Share embedding is enabled but hidden_size != embedding_size
2021-06-17 13:22:49.983 | INFO     | m3tl.utils:set_phase:478 - Setting phase to infer
2021-06-17 13:22:49.991 | CRITICAL | m3tl.model_fn:compile:271 - Initial lr: 0.0
2021-06-17 13:22:49.991 | CRITICAL | m3tl.model_fn:compile:272 - Train steps: 1
2021-06-17 13:22:49.992 | CRITICAL | m3tl.model_fn:compile:273 - Warmup steps: 0
2021-06-17 13:22:50.941 | INFO     | m3tl.utils:set_phase:478 - Setting phase to train
</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>WARNING: AutoGraph could not transform &lt;bound method Socket.send of &lt;zmq.sugar.socket.Socket object at 0x7fd82e8549f0&gt;&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained(&#39;name&#39;, output_attentions=True)`).
The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.
</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>1/1 [==============================] - ETA: 0s - mean_acc: 3.6298 - weibo_fake_cls_acc: 0.5000 - weibo_fake_ner_acc: 0.1250 - BertMultiTaskTop/weibo_fake_cls/losses/0: 0.8964 - BertMultiTaskTop/weibo_fake_multi_cls/losses/0: 0.9989 - BertMultiTaskTop/weibo_fake_ner/losses/0: 2.8322 - BertMultiTaskTop/weibo_masklm/losses/0: 10.0389 - BertMultiTaskTop/weibo_premask_mlm/losses/0: 10.0175</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>2021-06-17 13:23:00.005 | INFO     | m3tl.utils:set_phase:478 - Setting phase to eval
The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained(&#39;name&#39;, output_attentions=True)`).
The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.
2021-06-17 13:23:00.947 | INFO     | m3tl.utils:set_phase:478 - Setting phase to eval
The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained(&#39;name&#39;, output_attentions=True)`).
The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.
</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 1000 batches). You may need to use the repeat() function when building your dataset.
1/1 [==============================] - 12s 12s/step - mean_acc: 3.6298 - weibo_fake_cls_acc: 0.5000 - weibo_fake_ner_acc: 0.1250 - BertMultiTaskTop/weibo_fake_cls/losses/0: 0.8964 - BertMultiTaskTop/weibo_fake_multi_cls/losses/0: 0.9989 - BertMultiTaskTop/weibo_fake_ner/losses/0: 2.8322 - BertMultiTaskTop/weibo_masklm/losses/0: 10.0389 - BertMultiTaskTop/weibo_premask_mlm/losses/0: 10.0175 - val_loss: 14.9478 - val_mean_acc: 0.3333 - val_weibo_fake_cls_acc: 0.5000 - val_weibo_fake_ner_acc: 0.0000e+00 - val_BertMultiTaskTop/weibo_fake_cls/losses/0: 1.0952 - val_BertMultiTaskTop/weibo_fake_multi_cls/losses/0: 1.1085 - val_BertMultiTaskTop/weibo_fake_ner/losses/0: 3.0644 - val_BertMultiTaskTop/weibo_masklm/losses/0: 0.0000e+00
Model: &#34;BertMultiTask&#34;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
BertMultiTaskBody (BertMulti multiple                  4082696   
_________________________________________________________________
basic_mtl (BasicMTL)         multiple                  0         
_________________________________________________________________
BertMultiTaskTop (BertMultiT multiple                  13229575  
_________________________________________________________________
sum_loss_combination (SumLos multiple                  0         
=================================================================
Total params: 17,312,273
Trainable params: 17,312,267
Non-trainable params: 6
_________________________________________________________________
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Slow-train-test">Slow train test<a class="anchor-link" href="#Slow-train-test"> </a></h3>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Saving-model-for-prediction">Saving model for prediction<a class="anchor-link" href="#Saving-model-for-prediction"> </a></h2>
</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="create_tensorspec_from_shape_type" class="doc_header"><code>create_tensorspec_from_shape_type</code><a href="https://github.com/JayYip/m3tl/tree/master/m3tl/run_bert_multitask.py#L326" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>create_tensorspec_from_shape_type</code>(<strong><code>infered_shape_and_type</code></strong>:<code>Tuple</code>[<code>Dict</code>[<code>str</code>, <code>list</code>], <code>Dict</code>[<code>str</code>, <code>DType</code>]])</p>
</blockquote>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">test_tup</span> <span class="o">=</span> <span class="p">({</span>
    <span class="s1">&#39;text_input_ids&#39;</span><span class="p">:</span> <span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span>
    <span class="s1">&#39;text_mask&#39;</span><span class="p">:</span> <span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span>
    <span class="s1">&#39;text_segment_ids&#39;</span><span class="p">:</span> <span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span>
    <span class="s1">&#39;image_input_ids&#39;</span><span class="p">:</span> <span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">10</span><span class="p">],</span>
    <span class="s1">&#39;image_mask&#39;</span><span class="p">:</span> <span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="mi">5</span><span class="p">],</span>
    <span class="s1">&#39;image_segment_ids&#39;</span><span class="p">:</span> <span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="mi">5</span><span class="p">],</span>
    <span class="s1">&#39;class_input_ids&#39;</span><span class="p">:</span> <span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span>
    <span class="s1">&#39;class_mask&#39;</span><span class="p">:</span> <span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span>
    <span class="s1">&#39;class_segment_ids&#39;</span><span class="p">:</span> <span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="mi">1</span><span class="p">]},</span>
    <span class="p">{</span>
    <span class="s1">&#39;text_input_ids&#39;</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">int32</span><span class="p">,</span>
    <span class="s1">&#39;text_mask&#39;</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">int32</span><span class="p">,</span>
    <span class="s1">&#39;text_segment_ids&#39;</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">int32</span><span class="p">,</span>
    <span class="s1">&#39;image_input_ids&#39;</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span>
    <span class="s1">&#39;image_mask&#39;</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">int32</span><span class="p">,</span>
    <span class="s1">&#39;image_segment_ids&#39;</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">int32</span><span class="p">,</span>
    <span class="s1">&#39;class_input_ids&#39;</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">int32</span><span class="p">,</span>
    <span class="s1">&#39;class_mask&#39;</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">int32</span><span class="p">,</span>
    <span class="s1">&#39;class_segment_ids&#39;</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">int32</span><span class="p">})</span>


<span class="nb">print</span><span class="p">(</span><span class="n">create_tensorspec_from_shape_type</span><span class="p">(</span><span class="n">test_tup</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>{&#39;text_input_ids&#39;: TensorSpec(shape=(None, None), dtype=tf.int32, name=&#39;text_input_ids&#39;), &#39;text_mask&#39;: TensorSpec(shape=(None, None), dtype=tf.int32, name=&#39;text_mask&#39;), &#39;text_segment_ids&#39;: TensorSpec(shape=(None, None), dtype=tf.int32, name=&#39;text_segment_ids&#39;), &#39;image_input_ids&#39;: TensorSpec(shape=(None, None, None), dtype=tf.float32, name=&#39;image_input_ids&#39;), &#39;image_mask&#39;: TensorSpec(shape=(None, None), dtype=tf.int32, name=&#39;image_mask&#39;), &#39;image_segment_ids&#39;: TensorSpec(shape=(None, None), dtype=tf.int32, name=&#39;image_segment_ids&#39;), &#39;class_input_ids&#39;: TensorSpec(shape=(None, None), dtype=tf.int32, name=&#39;class_input_ids&#39;), &#39;class_mask&#39;: TensorSpec(shape=(None, None), dtype=tf.int32, name=&#39;class_mask&#39;), &#39;class_segment_ids&#39;: TensorSpec(shape=(None, None), dtype=tf.int32, name=&#39;class_segment_ids&#39;)}
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="trim_checkpoint_for_prediction" class="doc_header"><code>trim_checkpoint_for_prediction</code><a href="https://github.com/JayYip/m3tl/tree/master/m3tl/run_bert_multitask.py#L335" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>trim_checkpoint_for_prediction</code>(<strong><code>problem</code></strong>:<code>str</code>, <strong><code>input_dir</code></strong>:<code>str</code>, <strong><code>output_dir</code></strong>:<code>str</code>, <strong><code>problem_type_dict</code></strong>:<code>Dict</code>[<code>str</code>, <code>str</code>]=<em><code>None</code></em>, <strong><code>overwrite</code></strong>=<em><code>True</code></em>, <strong><code>fake_input_list</code></strong>=<em><code>None</code></em>, <strong><code>params</code></strong>=<em><code>None</code></em>, <strong><code>save_weights_only</code></strong>=<em><code>True</code></em>)</p>
</blockquote>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Minimize checkpoint size for prediction.</p>
<p>Since the original checkpoint contains optimizer's variable,
        for instance, if the use adam, the checkpoint size will
        be three times of the size of model weights. This function
        will remove those unused variables in prediction to save space.</p>
<p>Note: if the model is a multimodal model, you have to provide fake_input_list that
        mimic the structure of real input. Otherwise modal embeddings will be randomly initialized.</p>
<p>Args:</p>
<ul>
<li>problem (str): problem</li>
<li>input_dir (str): input dir</li>
<li>output_dir (str): output dir</li>
<li>problem_type_dict (Dict[str, str], optional): problem type dict. Defaults to None.</li>
<li>fake_input_list (List, optional): fake input list to create dummy dataset</li>
<li>params (Params, optional): params </li>
</ul>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">tf</span><span class="o">.</span><span class="n">get_logger</span><span class="p">()</span><span class="o">.</span><span class="n">setLevel</span><span class="p">(</span><span class="s1">&#39;ERROR&#39;</span><span class="p">)</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">m3tl.predefined_problems.test_data</span> <span class="kn">import</span> <span class="n">generate_fake_data</span>
<span class="n">fake_inputs</span> <span class="o">=</span> <span class="p">[</span><span class="n">v</span> <span class="k">for</span> <span class="n">v</span><span class="p">,</span> <span class="n">_</span> <span class="ow">in</span> <span class="n">generate_fake_data</span><span class="p">(</span><span class="n">output_format</span><span class="o">=</span><span class="s1">&#39;gen_dict_tuple&#39;</span><span class="p">)]</span>

<span class="c1"># save as SavedModel pb</span>
<span class="n">trim_checkpoint_for_prediction</span><span class="p">(</span><span class="n">problem</span><span class="o">=</span><span class="n">model</span><span class="o">.</span><span class="n">params</span><span class="o">.</span><span class="n">problem_str</span><span class="p">,</span> <span class="n">input_dir</span><span class="o">=</span><span class="n">model</span><span class="o">.</span><span class="n">params</span><span class="o">.</span><span class="n">ckpt_dir</span><span class="p">,</span>
    <span class="n">output_dir</span><span class="o">=</span><span class="n">model</span><span class="o">.</span><span class="n">params</span><span class="o">.</span><span class="n">ckpt_dir</span><span class="o">+</span><span class="s1">&#39;_pred&#39;</span><span class="p">,</span>
    <span class="n">problem_type_dict</span><span class="o">=</span><span class="n">problem_type_dict</span><span class="p">,</span> <span class="n">overwrite</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">fake_input_list</span><span class="o">=</span><span class="n">fake_inputs</span><span class="p">,</span> <span class="n">save_weights_only</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

<span class="n">trim_checkpoint_for_prediction</span><span class="p">(</span>
    <span class="n">problem</span><span class="o">=</span><span class="n">problem</span><span class="p">,</span> <span class="n">input_dir</span><span class="o">=</span><span class="n">model</span><span class="o">.</span><span class="n">params</span><span class="o">.</span><span class="n">ckpt_dir</span><span class="p">,</span>
    <span class="n">output_dir</span><span class="o">=</span><span class="n">model</span><span class="o">.</span><span class="n">params</span><span class="o">.</span><span class="n">ckpt_dir</span><span class="o">+</span><span class="s1">&#39;_pred&#39;</span><span class="p">,</span>
    <span class="n">problem_type_dict</span><span class="o">=</span><span class="n">problem_type_dict</span><span class="p">,</span> <span class="n">overwrite</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">fake_input_list</span><span class="o">=</span><span class="n">fake_inputs</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>2021-06-17 13:24:55.159 | INFO     | m3tl.base_params:register_multiple_problems:538 - Adding new problem weibo_fake_ner, problem type: seq_tag
2021-06-17 13:24:55.159 | INFO     | m3tl.base_params:register_multiple_problems:538 - Adding new problem weibo_cws, problem type: seq_tag
2021-06-17 13:24:55.160 | INFO     | m3tl.base_params:register_multiple_problems:538 - Adding new problem weibo_fake_multi_cls, problem type: multi_cls
2021-06-17 13:24:55.160 | INFO     | m3tl.base_params:register_multiple_problems:538 - Adding new problem weibo_fake_cls, problem type: cls
2021-06-17 13:24:55.161 | INFO     | m3tl.base_params:register_multiple_problems:538 - Adding new problem weibo_masklm, problem type: masklm
2021-06-17 13:24:55.161 | INFO     | m3tl.base_params:register_multiple_problems:538 - Adding new problem weibo_pretrain, problem type: pretrain
2021-06-17 13:24:55.164 | INFO     | m3tl.base_params:register_multiple_problems:538 - Adding new problem weibo_premask_mlm, problem type: premask_mlm
2021-06-17 13:24:55.165 | WARNING  | m3tl.base_params:assign_problem:634 - base_dir and dir_name arguments will be deprecated in the future. Please use model_dir instead.
2021-06-17 13:24:55.383 | CRITICAL | m3tl.embedding_layer.base:__init__:58 - Modal Type id mapping: 
 {
    &#34;array&#34;: 0,
    &#34;cate&#34;: 1,
    &#34;text&#34;: 2
}
2021-06-17 13:24:55.476 | WARNING  | m3tl.problem_types.masklm:__init__:41 - Share embedding is enabled but hidden_size != embedding_size
2021-06-17 13:24:55.615 | INFO     | m3tl.utils:set_phase:478 - Setting phase to infer
The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained(&#39;name&#39;, output_attentions=True)`).
The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.
2021-06-17 13:24:57.074 | CRITICAL | __main__:trim_checkpoint_for_prediction:43 - serving input sigantures: {&#39;text_input_ids&#39;: TensorSpec(shape=(None, None), dtype=tf.int32, name=&#39;text_input_ids&#39;), &#39;text_mask&#39;: TensorSpec(shape=(None, None), dtype=tf.int32, name=&#39;text_mask&#39;), &#39;text_segment_ids&#39;: TensorSpec(shape=(None, None), dtype=tf.int32, name=&#39;text_segment_ids&#39;), &#39;array_input_ids&#39;: TensorSpec(shape=(None, None, None), dtype=tf.float32, name=&#39;array_input_ids&#39;), &#39;array_mask&#39;: TensorSpec(shape=(None, None), dtype=tf.int32, name=&#39;array_mask&#39;), &#39;array_segment_ids&#39;: TensorSpec(shape=(None, None), dtype=tf.int32, name=&#39;array_segment_ids&#39;), &#39;cate_input_ids&#39;: TensorSpec(shape=(None, None), dtype=tf.int32, name=&#39;cate_input_ids&#39;), &#39;cate_mask&#39;: TensorSpec(shape=(None, None), dtype=tf.int32, name=&#39;cate_mask&#39;), &#39;cate_segment_ids&#39;: TensorSpec(shape=(None, None), dtype=tf.int32, name=&#39;cate_segment_ids&#39;)}
The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained(&#39;name&#39;, output_attentions=True)`).
The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.
The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained(&#39;name&#39;, output_attentions=True)`).
The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.
The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained(&#39;name&#39;, output_attentions=True)`).
The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.
The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained(&#39;name&#39;, output_attentions=True)`).
The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.
The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained(&#39;name&#39;, output_attentions=True)`).
The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.
The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained(&#39;name&#39;, output_attentions=True)`).
The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.
The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained(&#39;name&#39;, output_attentions=True)`).
The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.
The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained(&#39;name&#39;, output_attentions=True)`).
The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.
The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained(&#39;name&#39;, output_attentions=True)`).
The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.
The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained(&#39;name&#39;, output_attentions=True)`).
The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.
The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained(&#39;name&#39;, output_attentions=True)`).
The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.
The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained(&#39;name&#39;, output_attentions=True)`).
The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.
The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained(&#39;name&#39;, output_attentions=True)`).
The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.
The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained(&#39;name&#39;, output_attentions=True)`).
The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.
The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained(&#39;name&#39;, output_attentions=True)`).
The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.
The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained(&#39;name&#39;, output_attentions=True)`).
The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.
The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained(&#39;name&#39;, output_attentions=True)`).
The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.
The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained(&#39;name&#39;, output_attentions=True)`).
The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.
The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained(&#39;name&#39;, output_attentions=True)`).
The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.
The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained(&#39;name&#39;, output_attentions=True)`).
The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.
The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained(&#39;name&#39;, output_attentions=True)`).
The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.
The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained(&#39;name&#39;, output_attentions=True)`).
The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.
The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained(&#39;name&#39;, output_attentions=True)`).
The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.
The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained(&#39;name&#39;, output_attentions=True)`).
The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.
WARNING:absl:Found untraced functions such as embeddings_layer_call_fn, embeddings_layer_call_and_return_conditional_losses, position_embeddings_layer_call_fn, position_embeddings_layer_call_and_return_conditional_losses, token_type_embeddings_layer_call_fn while saving (showing 5 of 125). These functions will not be directly callable after loading.
WARNING:absl:Found untraced functions such as embeddings_layer_call_fn, embeddings_layer_call_and_return_conditional_losses, position_embeddings_layer_call_fn, position_embeddings_layer_call_and_return_conditional_losses, token_type_embeddings_layer_call_fn while saving (showing 5 of 125). These functions will not be directly callable after loading.
2021-06-17 13:25:39.080 | INFO     | m3tl.base_params:register_multiple_problems:538 - Adding new problem weibo_fake_ner, problem type: seq_tag
2021-06-17 13:25:39.080 | INFO     | m3tl.base_params:register_multiple_problems:538 - Adding new problem weibo_cws, problem type: seq_tag
2021-06-17 13:25:39.081 | INFO     | m3tl.base_params:register_multiple_problems:538 - Adding new problem weibo_fake_multi_cls, problem type: multi_cls
2021-06-17 13:25:39.082 | INFO     | m3tl.base_params:register_multiple_problems:538 - Adding new problem weibo_fake_cls, problem type: cls
2021-06-17 13:25:39.082 | INFO     | m3tl.base_params:register_multiple_problems:538 - Adding new problem weibo_masklm, problem type: masklm
2021-06-17 13:25:39.082 | INFO     | m3tl.base_params:register_multiple_problems:538 - Adding new problem weibo_pretrain, problem type: pretrain
2021-06-17 13:25:39.083 | INFO     | m3tl.base_params:register_multiple_problems:538 - Adding new problem weibo_premask_mlm, problem type: premask_mlm
2021-06-17 13:25:39.084 | WARNING  | m3tl.base_params:assign_problem:634 - base_dir and dir_name arguments will be deprecated in the future. Please use model_dir instead.
2021-06-17 13:25:39.306 | CRITICAL | m3tl.embedding_layer.base:__init__:58 - Modal Type id mapping: 
 {
    &#34;array&#34;: 0,
    &#34;cate&#34;: 1,
    &#34;text&#34;: 2
}
2021-06-17 13:25:39.404 | WARNING  | m3tl.problem_types.masklm:__init__:41 - Share embedding is enabled but hidden_size != embedding_size
2021-06-17 13:25:39.558 | INFO     | m3tl.utils:set_phase:478 - Setting phase to infer
The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained(&#39;name&#39;, output_attentions=True)`).
The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.
2021-06-17 13:25:40.708 | CRITICAL | __main__:trim_checkpoint_for_prediction:43 - serving input sigantures: {&#39;text_input_ids&#39;: TensorSpec(shape=(None, None), dtype=tf.int32, name=&#39;text_input_ids&#39;), &#39;text_mask&#39;: TensorSpec(shape=(None, None), dtype=tf.int32, name=&#39;text_mask&#39;), &#39;text_segment_ids&#39;: TensorSpec(shape=(None, None), dtype=tf.int32, name=&#39;text_segment_ids&#39;), &#39;array_input_ids&#39;: TensorSpec(shape=(None, None, None), dtype=tf.float32, name=&#39;array_input_ids&#39;), &#39;array_mask&#39;: TensorSpec(shape=(None, None), dtype=tf.int32, name=&#39;array_mask&#39;), &#39;array_segment_ids&#39;: TensorSpec(shape=(None, None), dtype=tf.int32, name=&#39;array_segment_ids&#39;), &#39;cate_input_ids&#39;: TensorSpec(shape=(None, None), dtype=tf.int32, name=&#39;cate_input_ids&#39;), &#39;cate_mask&#39;: TensorSpec(shape=(None, None), dtype=tf.int32, name=&#39;cate_mask&#39;), &#39;cate_segment_ids&#39;: TensorSpec(shape=(None, None), dtype=tf.int32, name=&#39;cate_segment_ids&#39;)}
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Eval">Eval<a class="anchor-link" href="#Eval"> </a></h2>
</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="eval_bert_multitask" class="doc_header"><code>eval_bert_multitask</code><a href="https://github.com/JayYip/m3tl/tree/master/m3tl/run_bert_multitask.py#L398" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>eval_bert_multitask</code>(<strong><code>problem</code></strong>=<em><code>'weibo_ner'</code></em>, <strong><code>num_gpus</code></strong>=<em><code>1</code></em>, <strong><code>model_dir</code></strong>=<em><code>''</code></em>, <strong><code>params</code></strong>=<em><code>None</code></em>, <strong><code>problem_type_dict</code></strong>=<em><code>None</code></em>, <strong><code>processing_fn_dict</code></strong>=<em><code>None</code></em>, <strong><code>model</code></strong>=<em><code>None</code></em>, <strong><code>run_eagerly</code></strong>=<em><code>False</code></em>)</p>
</blockquote>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Evaluate Multi-task Bert model</p>
<p>Keyword Arguments:</p>
<ul>
<li>problem (str, optional): problems to evaluate. Defaults to 'weibo_ner'.</li>
<li>num_gpus (int, optional): number of gpu to use. Defaults to 1.</li>
<li>model_dir (str, optional): model dir. Defaults to ''.</li>
<li>params (Params, optional): params. Defaults to None.</li>
<li>problem_type_dict (dict, optional): Key: problem name, value: problem type. Defaults to None.</li>
<li>processing_fn_dict (dict, optional): Key: problem name, value: problem data preprocessing fn. Defaults to None.</li>
<li>model (tf.keras.Model, optional): If not provided, it will be created with <a href="/m3tl/run_bert_multitask.html#create_keras_model"><code>create_keras_model</code></a>. Defaults to None.</li>
<li>run_eagerly (bool, optional): Whether to run model eagerly. Defaults to False.</li>
</ul>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">shutil</span>
<span class="n">shutil</span><span class="o">.</span><span class="n">rmtree</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">params</span><span class="o">.</span><span class="n">ckpt_dir</span><span class="p">)</span>

<span class="n">eval_bert_multitask</span><span class="p">(</span><span class="n">problem</span><span class="o">=</span><span class="n">problem</span><span class="p">,</span> <span class="n">params</span><span class="o">=</span><span class="n">params</span><span class="p">,</span>
                    <span class="n">problem_type_dict</span><span class="o">=</span><span class="n">problem_type_dict</span><span class="p">,</span> <span class="n">processing_fn_dict</span><span class="o">=</span><span class="n">processing_fn_dict</span><span class="p">,</span>
                    <span class="n">model_dir</span><span class="o">=</span><span class="n">model</span><span class="o">.</span><span class="n">params</span><span class="o">.</span><span class="n">ckpt_dir</span><span class="o">+</span><span class="s1">&#39;_pred&#39;</span><span class="p">)</span>

<span class="c1"># provide model instead of dir</span>
<span class="n">eval_bert_multitask</span><span class="p">(</span><span class="n">problem</span><span class="o">=</span><span class="n">problem</span><span class="p">,</span> <span class="n">params</span><span class="o">=</span><span class="n">params</span><span class="p">,</span>
                    <span class="n">problem_type_dict</span><span class="o">=</span><span class="n">problem_type_dict</span><span class="p">,</span> <span class="n">processing_fn_dict</span><span class="o">=</span><span class="n">processing_fn_dict</span><span class="p">,</span>
                    <span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>2021-06-15 20:28:35.752 | INFO     | m3tl.base_params:register_multiple_problems:538 - Adding new problem weibo_fake_ner, problem type: seq_tag
2021-06-15 20:28:35.753 | INFO     | m3tl.base_params:register_multiple_problems:538 - Adding new problem weibo_cws, problem type: seq_tag
2021-06-15 20:28:35.754 | INFO     | m3tl.base_params:register_multiple_problems:538 - Adding new problem weibo_fake_multi_cls, problem type: multi_cls
2021-06-15 20:28:35.754 | INFO     | m3tl.base_params:register_multiple_problems:538 - Adding new problem weibo_fake_cls, problem type: cls
2021-06-15 20:28:35.755 | INFO     | m3tl.base_params:register_multiple_problems:538 - Adding new problem weibo_masklm, problem type: masklm
2021-06-15 20:28:35.755 | INFO     | m3tl.base_params:register_multiple_problems:538 - Adding new problem weibo_pretrain, problem type: pretrain
2021-06-15 20:28:35.755 | INFO     | m3tl.base_params:register_multiple_problems:538 - Adding new problem weibo_premask_mlm, problem type: premask_mlm
2021-06-15 20:28:36.219 | INFO     | m3tl.input_fn:train_eval_input_fn:59 - sampling weights: 
2021-06-15 20:28:36.220 | INFO     | m3tl.input_fn:train_eval_input_fn:60 - {
    &#34;weibo_fake_cls_weibo_fake_ner&#34;: 0.2564102564102564,
    &#34;weibo_fake_multi_cls&#34;: 0.2564102564102564,
    &#34;weibo_masklm&#34;: 0.23076923076923078,
    &#34;weibo_premask_mlm&#34;: 0.2564102564102564
}
2021-06-15 20:28:37.241 | INFO     | m3tl.input_fn:train_eval_input_fn:59 - sampling weights: 
2021-06-15 20:28:37.243 | INFO     | m3tl.input_fn:train_eval_input_fn:60 - {
    &#34;weibo_fake_cls_weibo_fake_ner&#34;: 0.2564102564102564,
    &#34;weibo_fake_multi_cls&#34;: 0.2564102564102564,
    &#34;weibo_masklm&#34;: 0.23076923076923078,
    &#34;weibo_premask_mlm&#34;: 0.2564102564102564
}
2021-06-15 20:28:37.597 | CRITICAL | m3tl.embedding_layer.base:__init__:58 - Modal Type id mapping: 
 {
    &#34;array&#34;: 0,
    &#34;cate&#34;: 1,
    &#34;text&#34;: 2
}
2021-06-15 20:28:37.691 | WARNING  | m3tl.problem_types.masklm:__init__:41 - Share embedding is enabled but hidden_size != embedding_size
2021-06-15 20:28:37.723 | INFO     | m3tl.utils:set_phase:478 - Setting phase to infer
The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained(&#39;name&#39;, output_attentions=True)`).
The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.
2021-06-15 20:28:39.219 | CRITICAL | m3tl.model_fn:compile:271 - Initial lr: 0.0
2021-06-15 20:28:39.220 | CRITICAL | m3tl.model_fn:compile:272 - Train steps: 1
2021-06-15 20:28:39.220 | CRITICAL | m3tl.model_fn:compile:273 - Warmup steps: 0
2021-06-15 20:28:40.317 | INFO     | m3tl.utils:set_phase:478 - Setting phase to eval
The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained(&#39;name&#39;, output_attentions=True)`).
The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.
</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>3/3 [==============================] - 5s 21ms/step - loss: 22.2266 - mean_acc: 0.5357 - weibo_fake_cls_acc: 0.5000 - weibo_fake_ner_acc: 0.5714 - BertMultiTaskTop/weibo_fake_cls/losses/0: 0.2471 - BertMultiTaskTop/weibo_fake_multi_cls/losses/0: 0.5657 - BertMultiTaskTop/weibo_fake_ner/losses/0: 0.3361 - BertMultiTaskTop/weibo_masklm/losses/0: 10.0024 - BertMultiTaskTop/weibo_premask_mlm/losses/0: 9.9237
</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>2021-06-15 20:28:44.361 | INFO     | m3tl.base_params:register_multiple_problems:538 - Adding new problem weibo_fake_ner, problem type: seq_tag
2021-06-15 20:28:44.362 | INFO     | m3tl.base_params:register_multiple_problems:538 - Adding new problem weibo_cws, problem type: seq_tag
2021-06-15 20:28:44.363 | INFO     | m3tl.base_params:register_multiple_problems:538 - Adding new problem weibo_fake_multi_cls, problem type: multi_cls
2021-06-15 20:28:44.363 | INFO     | m3tl.base_params:register_multiple_problems:538 - Adding new problem weibo_fake_cls, problem type: cls
2021-06-15 20:28:44.363 | INFO     | m3tl.base_params:register_multiple_problems:538 - Adding new problem weibo_masklm, problem type: masklm
2021-06-15 20:28:44.364 | INFO     | m3tl.base_params:register_multiple_problems:538 - Adding new problem weibo_pretrain, problem type: pretrain
2021-06-15 20:28:44.364 | INFO     | m3tl.base_params:register_multiple_problems:538 - Adding new problem weibo_premask_mlm, problem type: premask_mlm
2021-06-15 20:28:44.805 | INFO     | m3tl.input_fn:train_eval_input_fn:59 - sampling weights: 
2021-06-15 20:28:44.806 | INFO     | m3tl.input_fn:train_eval_input_fn:60 - {
    &#34;weibo_fake_cls_weibo_fake_ner&#34;: 0.2564102564102564,
    &#34;weibo_fake_multi_cls&#34;: 0.2564102564102564,
    &#34;weibo_masklm&#34;: 0.23076923076923078,
    &#34;weibo_premask_mlm&#34;: 0.2564102564102564
}
2021-06-15 20:28:45.832 | INFO     | m3tl.input_fn:train_eval_input_fn:59 - sampling weights: 
2021-06-15 20:28:45.833 | INFO     | m3tl.input_fn:train_eval_input_fn:60 - {
    &#34;weibo_fake_cls_weibo_fake_ner&#34;: 0.2564102564102564,
    &#34;weibo_fake_multi_cls&#34;: 0.2564102564102564,
    &#34;weibo_masklm&#34;: 0.23076923076923078,
    &#34;weibo_premask_mlm&#34;: 0.2564102564102564
}
</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>3/3 [==============================] - 1s 21ms/step - loss: 23.1741 - mean_acc: 0.4241 - weibo_fake_cls_acc: 0.5000 - weibo_fake_ner_acc: 0.2857 - BertMultiTaskTop/weibo_fake_cls/losses/0: 1.4929 - BertMultiTaskTop/weibo_fake_multi_cls/losses/0: 0.2098 - BertMultiTaskTop/weibo_fake_ner/losses/0: 1.7419 - BertMultiTaskTop/weibo_masklm/losses/0: 10.0072 - BertMultiTaskTop/weibo_premask_mlm/losses/0: 9.7933
</pre>
</div>
</div>

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>{&#39;loss&#39;: 23.17413330078125,
 &#39;mean_acc&#39;: 0.4241071343421936,
 &#39;weibo_fake_cls_acc&#39;: 0.5,
 &#39;weibo_fake_ner_acc&#39;: 0.2857142984867096,
 &#39;BertMultiTaskTop/weibo_fake_cls/losses/0&#39;: 1.8408839702606201,
 &#39;BertMultiTaskTop/weibo_fake_multi_cls/losses/0&#39;: 0.0,
 &#39;BertMultiTaskTop/weibo_fake_ner/losses/0&#39;: 1.7550007104873657,
 &#39;BertMultiTaskTop/weibo_masklm/losses/0&#39;: 10.002845764160156,
 &#39;BertMultiTaskTop/weibo_premask_mlm/losses/0&#39;: 9.788535118103027}</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Predict">Predict<a class="anchor-link" href="#Predict"> </a></h2>
</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">arr_to_str</span><span class="p">(</span><span class="n">inp_arr</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
    <span class="n">l</span> <span class="o">=</span> <span class="n">inp_arr</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>
    <span class="n">l</span> <span class="o">=</span> <span class="p">[</span><span class="n">json</span><span class="o">.</span><span class="n">dumps</span><span class="p">(</span><span class="n">f</span><span class="p">)</span> <span class="k">for</span> <span class="n">f</span> <span class="ow">in</span> <span class="n">l</span><span class="p">]</span>
    <span class="k">return</span> <span class="n">l</span>


<span class="k">def</span> <span class="nf">decode_predictions</span><span class="p">(</span><span class="n">pred</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">],</span> <span class="n">params</span><span class="p">:</span> <span class="n">Params</span><span class="p">,</span> <span class="n">array_as_str</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Union</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">float</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="nb">list</span><span class="p">,</span> <span class="nb">str</span><span class="p">]]:</span>
    <span class="n">parsed_pred</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">()</span>
    <span class="n">problem_list</span> <span class="o">=</span> <span class="n">params</span><span class="o">.</span><span class="n">problem_list</span>
    <span class="n">label_encoder_dict</span> <span class="o">=</span> <span class="p">{</span><span class="n">p</span><span class="p">:</span> <span class="n">get_or_make_label_encoder</span><span class="p">(</span>
        <span class="n">params</span><span class="o">=</span><span class="n">params</span><span class="p">,</span> <span class="n">problem</span><span class="o">=</span><span class="n">p</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="n">PREDICT</span><span class="p">)</span> <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">problem_list</span><span class="p">}</span>
    <span class="k">for</span> <span class="n">problem</span><span class="p">,</span> <span class="n">problem_pred_array</span> <span class="ow">in</span> <span class="n">pred</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>

        <span class="c1"># addtional outputs</span>
        <span class="k">if</span> <span class="n">problem</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">problem_list</span><span class="p">:</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">problem_pred_array</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">):</span>
                <span class="k">if</span> <span class="n">array_as_str</span><span class="p">:</span>
                    <span class="n">parsed_pred</span><span class="p">[</span><span class="n">problem</span><span class="p">]</span> <span class="o">=</span> <span class="n">arr_to_str</span><span class="p">(</span><span class="n">problem_pred_array</span><span class="p">)</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">parsed_pred</span><span class="p">[</span><span class="n">problem</span><span class="p">]</span> <span class="o">=</span> <span class="n">problem_pred_array</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">parsed_pred</span><span class="p">[</span><span class="n">problem</span><span class="p">]</span> <span class="o">=</span> <span class="n">problem_pred_array</span>
            <span class="k">continue</span>

        <span class="n">label_encoder</span> <span class="o">=</span> <span class="n">label_encoder_dict</span><span class="p">[</span><span class="n">problem</span><span class="p">]</span>

        <span class="n">support_problem_type</span> <span class="o">=</span> <span class="p">[</span>
            <span class="s1">&#39;multi_cls&#39;</span><span class="p">,</span>
            <span class="s1">&#39;cls&#39;</span><span class="p">,</span>
            <span class="s1">&#39;seq_tag&#39;</span><span class="p">,</span>
            <span class="s1">&#39;regression&#39;</span><span class="p">,</span>
            <span class="s1">&#39;masklm&#39;</span><span class="p">,</span>
            <span class="s1">&#39;premask_mlm&#39;</span><span class="p">,</span>
            <span class="s1">&#39;vectorfit&#39;</span>
        <span class="p">]</span>

        <span class="n">problem_type</span> <span class="o">=</span> <span class="n">params</span><span class="o">.</span><span class="n">get_problem_type</span><span class="p">(</span><span class="n">problem</span><span class="o">=</span><span class="n">problem</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">problem_type</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">support_problem_type</span><span class="p">:</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="s2">&quot;trying to decode prediction of unsupported problem type&quot;</span>
            <span class="s2">&quot; </span><span class="si">{}</span><span class="s2">, if any error raised, please disable decode prediction.&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">problem_type</span><span class="p">))</span>

        <span class="n">is_multi_cls</span> <span class="o">=</span> <span class="n">params</span><span class="o">.</span><span class="n">get_problem_type</span><span class="p">(</span><span class="n">problem</span><span class="o">=</span><span class="n">problem</span><span class="p">)</span> <span class="o">==</span> <span class="s1">&#39;multi_cls&#39;</span>
        <span class="n">is_cls</span> <span class="o">=</span> <span class="n">params</span><span class="o">.</span><span class="n">get_problem_type</span><span class="p">(</span><span class="n">problem</span><span class="o">=</span><span class="n">problem</span><span class="p">)</span> <span class="o">==</span> <span class="s1">&#39;cls&#39;</span>
        <span class="n">is_seq_tag</span> <span class="o">=</span> <span class="n">params</span><span class="o">.</span><span class="n">get_problem_type</span><span class="p">(</span><span class="n">problem</span><span class="o">=</span><span class="n">problem</span><span class="p">)</span> <span class="o">==</span> <span class="s1">&#39;seq_tag&#39;</span>
        <span class="n">is_regression</span> <span class="o">=</span> <span class="n">params</span><span class="o">.</span><span class="n">get_problem_type</span><span class="p">(</span>
            <span class="n">problem</span><span class="o">=</span><span class="n">problem</span><span class="p">)</span> <span class="o">==</span> <span class="s1">&#39;regression&#39;</span>

        <span class="k">if</span> <span class="n">is_regression</span><span class="p">:</span>
            <span class="n">parsed_pred</span><span class="p">[</span><span class="n">problem</span><span class="p">]</span> <span class="o">=</span> <span class="n">problem_pred_array</span>
            <span class="k">continue</span>

        <span class="c1"># get pred from prob</span>
        <span class="k">if</span> <span class="n">is_multi_cls</span><span class="p">:</span>
            <span class="n">problem_pred</span> <span class="o">=</span> <span class="n">problem_pred_array</span> <span class="o">&gt;=</span> <span class="mf">0.5</span>
        <span class="k">elif</span> <span class="n">is_cls</span> <span class="ow">or</span> <span class="n">is_seq_tag</span><span class="p">:</span>
            <span class="n">problem_pred</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">problem_pred_array</span><span class="p">,</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
            <span class="c1"># problem_pred = problem_pred_array</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">problem_pred</span> <span class="o">=</span> <span class="n">problem_pred_array</span>

        <span class="c1"># sequence labels</span>
        <span class="k">if</span> <span class="n">is_seq_tag</span><span class="p">:</span>
            <span class="n">parsed_problem_pred</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">apply_along_axis</span><span class="p">(</span>
                <span class="n">label_encoder</span><span class="o">.</span><span class="n">inverse_transform</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">arr</span><span class="o">=</span><span class="n">problem_pred</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">label_encoder</span><span class="p">,</span> <span class="n">MultiLabelBinarizer</span><span class="p">)</span> <span class="ow">or</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">label_encoder</span><span class="p">,</span> <span class="n">LabelEncoder</span><span class="p">):</span>
                <span class="n">parsed_problem_pred</span> <span class="o">=</span> <span class="n">label_encoder</span><span class="o">.</span><span class="n">inverse_transform</span><span class="p">(</span>
                    <span class="n">problem_pred</span><span class="p">)</span>
            <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">label_encoder</span><span class="p">,</span> <span class="n">PreTrainedTokenizer</span><span class="p">):</span>
                <span class="n">parsed_problem_pred</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">apply_along_axis</span><span class="p">(</span>
                    <span class="n">label_encoder</span><span class="o">.</span><span class="n">convert_ids_to_tokens</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">arr</span><span class="o">=</span><span class="n">problem_pred</span>
                <span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">parsed_problem_pred</span> <span class="o">=</span> <span class="n">problem_pred_array</span>

        <span class="n">parsed_pred</span><span class="p">[</span><span class="n">problem</span><span class="p">]</span> <span class="o">=</span> <span class="n">parsed_problem_pred</span>
    <span class="k">return</span> <span class="n">parsed_pred</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="predict_bert_multitask" class="doc_header"><code>predict_bert_multitask</code><a href="https://github.com/JayYip/m3tl/tree/master/m3tl/run_bert_multitask.py#L427" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>predict_bert_multitask</code>(<strong><code>inputs</code></strong>, <strong><code>problem</code></strong>=<em><code>'weibo_ner'</code></em>, <strong><code>model_dir</code></strong>=<em><code>''</code></em>, <strong><code>params</code></strong>:<a href="/m3tl/1_params.html#Params"><code>Params</code></a>=<em><code>None</code></em>, <strong><code>problem_type_dict</code></strong>:<code>Dict</code>[<code>str</code>, <code>str</code>]=<em><code>None</code></em>, <strong><code>processing_fn_dict</code></strong>:<code>Dict</code>[<code>str</code>, <code>Callable</code>]=<em><code>None</code></em>, <strong><code>model</code></strong>:<code>Model</code>=<em><code>None</code></em>, <strong><code>return_model</code></strong>=<em><code>False</code></em>, <strong><code>run_eagerly</code></strong>=<em><code>False</code></em>, <strong><code>mirrored_strategy</code></strong>=<em><code>None</code></em>, <strong><code>decode_prediction</code></strong>=<em><code>False</code></em>)</p>
</blockquote>
<p>Use Multi-task Bert model to do prediction</p>
<p>Args:</p>
<ul>
<li>inputs (Iterable): Iterable of inputs</li>
<li>problem (str, optional): problems to predict. Defaults to 'weibo_ner'.</li>
<li>model_dir (str, optional): model dir. Defaults to ''.</li>
<li>params (Params, optional): params. Defaults to None.</li>
<li>problem_type_dict (Dict[str, str], optional): Key: problem name, value: problem type.. Defaults to None.</li>
<li>processing_fn_dict (Dict[str, Callable], optional): Key: problem name, value: problem data preprocessing fn. Defaults to None.</li>
<li>model (tf.keras.Model, optional): If not provided, it will be created with <a href="/m3tl/run_bert_multitask.html#create_keras_model"><code>create_keras_model</code></a>. Defaults to None.</li>
<li>return_model (bool, optional): Whether return model, if True, function will return (pred, model) tuple. Defaults to False.</li>
<li>run_eagerly (bool, optional): Whether to run model eagerly. Defaults to False.</li>
<li>mirrored_strategy (optional): mirrored strategy for distribute prediction. Defaults to None.</li>
<li>decode_prediction (bool, optional): whether to decode predictions. Defaults to False.</li>
</ul>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">pred</span><span class="p">,</span> <span class="n">model</span> <span class="o">=</span> <span class="n">predict_bert_multitask</span><span class="p">(</span>
    <span class="n">problem</span><span class="o">=</span><span class="s1">&#39;weibo_fake_ner&#39;</span><span class="p">,</span>
    <span class="n">inputs</span><span class="o">=</span><span class="n">fake_inputs</span><span class="o">*</span><span class="mi">20</span><span class="p">,</span> <span class="n">model_dir</span><span class="o">=</span><span class="n">model</span><span class="o">.</span><span class="n">params</span><span class="o">.</span><span class="n">ckpt_dir</span><span class="p">,</span>
    <span class="n">problem_type_dict</span><span class="o">=</span><span class="n">problem_type_dict</span><span class="p">,</span>
    <span class="n">processing_fn_dict</span><span class="o">=</span><span class="n">processing_fn_dict</span><span class="p">,</span> <span class="n">return_model</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">params</span><span class="o">=</span><span class="n">params</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>2021-06-15 20:28:53.975 | INFO     | m3tl.utils:set_phase:478 - Setting phase to infer
2021-06-15 20:28:53.976 | INFO     | m3tl.base_params:register_multiple_problems:538 - Adding new problem weibo_fake_ner, problem type: seq_tag
2021-06-15 20:28:53.977 | INFO     | m3tl.base_params:register_multiple_problems:538 - Adding new problem weibo_cws, problem type: seq_tag
2021-06-15 20:28:53.977 | INFO     | m3tl.base_params:register_multiple_problems:538 - Adding new problem weibo_fake_multi_cls, problem type: multi_cls
2021-06-15 20:28:53.978 | INFO     | m3tl.base_params:register_multiple_problems:538 - Adding new problem weibo_fake_cls, problem type: cls
2021-06-15 20:28:53.978 | INFO     | m3tl.base_params:register_multiple_problems:538 - Adding new problem weibo_masklm, problem type: masklm
2021-06-15 20:28:53.978 | INFO     | m3tl.base_params:register_multiple_problems:538 - Adding new problem weibo_pretrain, problem type: pretrain
2021-06-15 20:28:53.979 | INFO     | m3tl.base_params:register_multiple_problems:538 - Adding new problem weibo_premask_mlm, problem type: premask_mlm
2021-06-15 20:28:54.017 | INFO     | __main__:predict_bert_multitask:39 - Checkpoint dir: models/weibo_fake_cls_weibo_fake_multi_cls_weibo_fake_ner_weibo_masklm_weibo_premask_mlm_ckpt_pred
2021-06-15 20:28:59.407 | CRITICAL | m3tl.embedding_layer.base:__init__:58 - Modal Type id mapping: 
 {
    &#34;array&#34;: 0,
    &#34;cate&#34;: 1,
    &#34;text&#34;: 2
}
2021-06-15 20:28:59.474 | INFO     | m3tl.utils:set_phase:478 - Setting phase to infer
The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained(&#39;name&#39;, output_attentions=True)`).
The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.
2021-06-15 20:29:00.488 | INFO     | m3tl.utils:set_phase:478 - Setting phase to infer
The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained(&#39;name&#39;, output_attentions=True)`).
The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

</div>
 

