---

title: LossCombinationStrategyBase


keywords: fastai
sidebar: home_sidebar



nb_path: "source_nbs/16-00_loss_combination_strategy.ipynb"
---
<!--

#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: source_nbs/16-00_loss_combination_strategy.ipynb
# command to build the docs after a change: nbdev_build_docs

-->

<div class="container" id="notebook-container">
        
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="LossCombinationStrategyBase" class="doc_header"><code>class</code> <code>LossCombinationStrategyBase</code><a href="https://github.com/JayYip/m3tl/tree/master/m3tl/loss_strategy/base.py#L15" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>LossCombinationStrategyBase</code>(<strong>*<code>args</code></strong>, <strong>**<code>kwargs</code></strong>) :: <code>Model</code></p>
</blockquote>
<p><code>Model</code> groups layers into an object with training and inference features.</p>
<p>Arguments:
    inputs: The input(s) of the model: a <code>keras.Input</code> object or list of
        <code>keras.Input</code> objects.
    outputs: The output(s) of the model. See Functional API example below.
    name: String, the name of the model.</p>
<p>There are two ways to instantiate a <code>Model</code>:</p>
<p>1 - With the "Functional API", where you start from <code>Input</code>,
you chain layer calls to specify the model's forward pass,
and finally you create your model from inputs and outputs:</p>
<div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>

<span class="n">inputs</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">Input</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,))</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">relu</span><span class="p">)(</span><span class="n">inputs</span><span class="p">)</span>
<span class="n">outputs</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">softmax</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">Model</span><span class="p">(</span><span class="n">inputs</span><span class="o">=</span><span class="n">inputs</span><span class="p">,</span> <span class="n">outputs</span><span class="o">=</span><span class="n">outputs</span><span class="p">)</span>
</pre></div>
<p>2 - By subclassing the <code>Model</code> class: in that case, you should define your
layers in <code>__init__</code> and you should implement the model's forward pass
in <code>call</code>.</p>
<div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>

<span class="k">class</span> <span class="nc">MyModel</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">Model</span><span class="p">):</span>

  <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="nb">super</span><span class="p">(</span><span class="n">MyModel</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">dense1</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">relu</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">dense2</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">softmax</span><span class="p">)</span>

  <span class="k">def</span> <span class="nf">call</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">):</span>
    <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dense1</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">dense2</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">MyModel</span><span class="p">()</span>
</pre></div>
<p>If you subclass <code>Model</code>, you can optionally have
a <code>training</code> argument (boolean) in <code>call</code>, which you can use to specify
a different behavior in training and inference:</p>
<div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>

<span class="k">class</span> <span class="nc">MyModel</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">Model</span><span class="p">):</span>

  <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="nb">super</span><span class="p">(</span><span class="n">MyModel</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">dense1</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">relu</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">dense2</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">softmax</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="mf">0.5</span><span class="p">)</span>

  <span class="k">def</span> <span class="nf">call</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">training</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
    <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dense1</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">training</span><span class="p">:</span>
      <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">training</span><span class="o">=</span><span class="n">training</span><span class="p">)</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">dense2</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">MyModel</span><span class="p">()</span>
</pre></div>
<p>Once the model is created, you can config the model with losses and metrics
with <code>model.compile()</code>, train the model with <code>model.fit()</code>, or use the model
to do prediction with <code>model.predict()</code>.</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="SumLossCombination" class="doc_header"><code>class</code> <code>SumLossCombination</code><a href="https://github.com/JayYip/m3tl/tree/master/m3tl/loss_strategy/base.py#L60" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>SumLossCombination</code>(<strong>*<code>args</code></strong>, <strong>**<code>kwargs</code></strong>) :: <a href="/m3tl/16-00_loss_combination_strategy.html#LossCombinationStrategyBase"><code>LossCombinationStrategyBase</code></a></p>
</blockquote>
<p><code>Model</code> groups layers into an object with training and inference features.</p>
<p>Arguments:
    inputs: The input(s) of the model: a <code>keras.Input</code> object or list of
        <code>keras.Input</code> objects.
    outputs: The output(s) of the model. See Functional API example below.
    name: String, the name of the model.</p>
<p>There are two ways to instantiate a <code>Model</code>:</p>
<p>1 - With the "Functional API", where you start from <code>Input</code>,
you chain layer calls to specify the model's forward pass,
and finally you create your model from inputs and outputs:</p>
<div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>

<span class="n">inputs</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">Input</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,))</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">relu</span><span class="p">)(</span><span class="n">inputs</span><span class="p">)</span>
<span class="n">outputs</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">softmax</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">Model</span><span class="p">(</span><span class="n">inputs</span><span class="o">=</span><span class="n">inputs</span><span class="p">,</span> <span class="n">outputs</span><span class="o">=</span><span class="n">outputs</span><span class="p">)</span>
</pre></div>
<p>2 - By subclassing the <code>Model</code> class: in that case, you should define your
layers in <code>__init__</code> and you should implement the model's forward pass
in <code>call</code>.</p>
<div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>

<span class="k">class</span> <span class="nc">MyModel</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">Model</span><span class="p">):</span>

  <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="nb">super</span><span class="p">(</span><span class="n">MyModel</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">dense1</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">relu</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">dense2</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">softmax</span><span class="p">)</span>

  <span class="k">def</span> <span class="nf">call</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">):</span>
    <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dense1</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">dense2</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">MyModel</span><span class="p">()</span>
</pre></div>
<p>If you subclass <code>Model</code>, you can optionally have
a <code>training</code> argument (boolean) in <code>call</code>, which you can use to specify
a different behavior in training and inference:</p>
<div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>

<span class="k">class</span> <span class="nc">MyModel</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">Model</span><span class="p">):</span>

  <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="nb">super</span><span class="p">(</span><span class="n">MyModel</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">dense1</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">relu</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">dense2</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">softmax</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="mf">0.5</span><span class="p">)</span>

  <span class="k">def</span> <span class="nf">call</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">training</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
    <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dense1</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">training</span><span class="p">:</span>
      <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">training</span><span class="o">=</span><span class="n">training</span><span class="p">)</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">dense2</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">MyModel</span><span class="p">()</span>
</pre></div>
<p>Once the model is created, you can config the model with losses and metrics
with <code>model.compile()</code>, train the model with <code>model.fit()</code>, or use the model
to do prediction with <code>model.predict()</code>.</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">m3tl.test_base</span> <span class="kn">import</span> <span class="n">TestBase</span>
<span class="kn">from</span> <span class="nn">m3tl.special_tokens</span> <span class="kn">import</span> <span class="n">TRAIN</span>
<span class="kn">from</span> <span class="nn">m3tl.utils</span> <span class="kn">import</span> <span class="n">create_dict_from_nested_model</span>

<span class="n">tb</span> <span class="o">=</span> <span class="n">TestBase</span><span class="p">()</span>
<span class="n">tb</span><span class="o">.</span><span class="n">test_loss_combination_strategy</span><span class="p">(</span><span class="n">loss_combination_strategy_name</span><span class="o">=</span><span class="s1">&#39;sum&#39;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>2021-06-12 22:06:32.702 | INFO     | m3tl.base_params:register_multiple_problems:526 - Adding new problem weibo_fake_ner, problem type: seq_tag
2021-06-12 22:06:32.702 | INFO     | m3tl.base_params:register_multiple_problems:526 - Adding new problem weibo_fake_multi_cls, problem type: multi_cls
2021-06-12 22:06:32.703 | INFO     | m3tl.base_params:register_multiple_problems:526 - Adding new problem weibo_fake_cls, problem type: cls
2021-06-12 22:06:32.703 | INFO     | m3tl.base_params:register_multiple_problems:526 - Adding new problem weibo_masklm, problem type: masklm
2021-06-12 22:06:32.703 | INFO     | m3tl.base_params:register_multiple_problems:526 - Adding new problem weibo_fake_regression, problem type: regression
2021-06-12 22:06:32.704 | INFO     | m3tl.base_params:register_multiple_problems:526 - Adding new problem weibo_fake_vector_fit, problem type: vector_fit
2021-06-12 22:06:32.704 | INFO     | m3tl.base_params:register_multiple_problems:526 - Adding new problem weibo_premask_mlm, problem type: premask_mlm
2021-06-12 22:06:32.705 | INFO     | m3tl.base_params:register_multiple_problems:526 - Adding new problem fake_contrastive_learning, problem type: contrastive_learning
2021-06-12 22:06:32.705 | WARNING  | m3tl.base_params:assign_problem:620 - base_dir and dir_name arguments will be deprecated in the future. Please use model_dir instead.
2021-06-12 22:06:32.706 | WARNING  | m3tl.base_params:prepare_dir:364 - bert_config not exists. will load model from huggingface checkpoint.
2021-06-12 22:06:38.983 | WARNING  | m3tl.read_write_tfrecord:chain_processed_data:248 - Chaining problems with &amp; may consume a lot of memory if data is not pyspark RDD.
2021-06-12 22:06:38.999 | DEBUG    | m3tl.read_write_tfrecord:_write_fn:134 - Writing /tmp/tmpnn8s6_dc/weibo_fake_cls_weibo_fake_ner_weibo_fake_regression_weibo_fake_vector_fit/train_00000.tfrecord
2021-06-12 22:06:39.075 | WARNING  | m3tl.read_write_tfrecord:chain_processed_data:248 - Chaining problems with &amp; may consume a lot of memory if data is not pyspark RDD.
2021-06-12 22:06:39.090 | DEBUG    | m3tl.read_write_tfrecord:_write_fn:134 - Writing /tmp/tmpnn8s6_dc/weibo_fake_cls_weibo_fake_ner_weibo_fake_regression_weibo_fake_vector_fit/eval_00000.tfrecord
2021-06-12 22:06:39.122 | DEBUG    | m3tl.read_write_tfrecord:_write_fn:134 - Writing /tmp/tmpnn8s6_dc/weibo_fake_multi_cls/train_00000.tfrecord
2021-06-12 22:06:39.147 | DEBUG    | m3tl.read_write_tfrecord:_write_fn:134 - Writing /tmp/tmpnn8s6_dc/weibo_fake_multi_cls/eval_00000.tfrecord
2021-06-12 22:06:39.223 | DEBUG    | m3tl.read_write_tfrecord:_write_fn:134 - Writing /tmp/tmpnn8s6_dc/weibo_masklm/train_00000.tfrecord
2021-06-12 22:06:39.272 | DEBUG    | m3tl.read_write_tfrecord:_write_fn:134 - Writing /tmp/tmpnn8s6_dc/weibo_masklm/eval_00000.tfrecord
2021-06-12 22:06:39.336 | DEBUG    | m3tl.read_write_tfrecord:_write_fn:134 - Writing /tmp/tmpnn8s6_dc/weibo_premask_mlm/train_00000.tfrecord
2021-06-12 22:06:39.398 | DEBUG    | m3tl.read_write_tfrecord:_write_fn:134 - Writing /tmp/tmpnn8s6_dc/weibo_premask_mlm/eval_00000.tfrecord
2021-06-12 22:06:39.416 | DEBUG    | m3tl.read_write_tfrecord:_write_fn:134 - Writing /tmp/tmpnn8s6_dc/fake_contrastive_learning/train_00000.tfrecord
2021-06-12 22:06:39.433 | DEBUG    | m3tl.read_write_tfrecord:_write_fn:134 - Writing /tmp/tmpnn8s6_dc/fake_contrastive_learning/eval_00000.tfrecord
2021-06-12 22:06:40.458 | INFO     | m3tl.input_fn:train_eval_input_fn:56 - sampling weights: 
2021-06-12 22:06:40.459 | INFO     | m3tl.input_fn:train_eval_input_fn:57 - {
    &#34;weibo_fake_cls_weibo_fake_ner_weibo_fake_regression_weibo_fake_vector_fit&#34;: 0.20408163265306123,
    &#34;weibo_fake_multi_cls&#34;: 0.20408163265306123,
    &#34;weibo_masklm&#34;: 0.1836734693877551,
    &#34;weibo_premask_mlm&#34;: 0.20408163265306123,
    &#34;fake_contrastive_learning&#34;: 0.20408163265306123
}
2021-06-12 22:06:41.120 | INFO     | m3tl.input_fn:train_eval_input_fn:56 - sampling weights: 
2021-06-12 22:06:41.120 | INFO     | m3tl.input_fn:train_eval_input_fn:57 - {
    &#34;weibo_fake_cls_weibo_fake_ner_weibo_fake_regression_weibo_fake_vector_fit&#34;: 0.20408163265306123,
    &#34;weibo_fake_multi_cls&#34;: 0.20408163265306123,
    &#34;weibo_masklm&#34;: 0.1836734693877551,
    &#34;weibo_premask_mlm&#34;: 0.20408163265306123,
    &#34;fake_contrastive_learning&#34;: 0.20408163265306123
}
404 Client Error: Not Found for url: https://huggingface.co/voidful/albert_chinese_tiny/resolve/main/tf_model.h5
Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFAlbertModel: [&#39;predictions.LayerNorm.bias&#39;, &#39;predictions.dense.weight&#39;, &#39;predictions.LayerNorm.weight&#39;, &#39;predictions.bias&#39;, &#39;predictions.decoder.weight&#39;, &#39;predictions.decoder.bias&#39;, &#39;predictions.dense.bias&#39;]
- This IS expected if you are initializing TFAlbertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing TFAlbertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).
All the weights of TFAlbertModel were initialized from the PyTorch model.
If your task is similar to the task the model of the checkpoint was trained on, you can already use TFAlbertModel for predictions without further training.
2021-06-12 22:06:45.703 | CRITICAL | m3tl.embedding_layer.base:__init__:58 - Modal Type id mapping: 
 {
    &#34;array&#34;: 0,
    &#34;cate&#34;: 1,
    &#34;text&#34;: 2
}
2021-06-12 22:06:45.823 | WARNING  | m3tl.problem_types.masklm:__init__:41 - Share embedding is enabled but hidden_size != embedding_size
2021-06-12 22:06:45.853 | WARNING  | m3tl.problem_types.contrastive_learning:get_contrastive_learning_model:86 - None not match any contrastive learning model, using SimCSE
2021-06-12 22:06:45.897 | CRITICAL | m3tl.model_fn:compile:271 - Initial lr: 0.0
2021-06-12 22:06:45.897 | CRITICAL | m3tl.model_fn:compile:272 - Train steps: 0
2021-06-12 22:06:45.898 | CRITICAL | m3tl.model_fn:compile:273 - Warmup steps: 0
</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Epoch 1/2
WARNING: AutoGraph could not transform &lt;bound method BertMultiTaskBody.call of &lt;m3tl.model_fn.BertMultiTaskBody object at 0x7fd2d617b290&gt;&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: invalid value for &#34;node&#34;: expected &#34;ast.AST&#34;, got &#34;&lt;class &#39;NoneType&#39;&gt;&#34;; to visit lists of nodes, use &#34;visit_block&#34; instead
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
WARNING: AutoGraph could not transform &lt;bound method Socket.send of &lt;zmq.sugar.socket.Socket object at 0x7fd3e16839f0&gt;&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained(&#39;name&#39;, output_attentions=True)`).
The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.
</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>1/1 [==============================] - ETA: 0s - mean_acc: 2.0046 - fake_contrastive_learning_acc: 0.1667 - weibo_fake_cls_acc: 0.4286 - weibo_fake_ner_acc: 0.1688 - weibo_fake_regression_neg_mse: -1.2120 - weibo_fake_vector_fit_cos_sim: -0.3722 - BertMultiTaskTop/fake_contrastive_learning/simcse/losses/0: 2.4941 - BertMultiTaskTop/weibo_fake_cls/losses/0: 1.0909 - BertMultiTaskTop/weibo_fake_multi_cls/losses/0: 0.4924 - BertMultiTaskTop/weibo_fake_ner/losses/0: 1.4930 - BertMultiTaskTop/weibo_fake_regression/losses/0: 1.2120 - BertMultiTaskTop/weibo_fake_vector_fit/losses/0: 0.3722 - BertMultiTaskTop/weibo_masklm/losses/0: 9.9305 - BertMultiTaskTop/weibo_premask_mlm/losses/0: 9.7947</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained(&#39;name&#39;, output_attentions=True)`).
The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.
</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>1/1 [==============================] - 24s 24s/step - mean_acc: 2.0046 - fake_contrastive_learning_acc: 0.1667 - weibo_fake_cls_acc: 0.4286 - weibo_fake_ner_acc: 0.1688 - weibo_fake_regression_neg_mse: -1.2120 - weibo_fake_vector_fit_cos_sim: -0.3722 - BertMultiTaskTop/fake_contrastive_learning/simcse/losses/0: 2.4941 - BertMultiTaskTop/weibo_fake_cls/losses/0: 1.0909 - BertMultiTaskTop/weibo_fake_multi_cls/losses/0: 0.4924 - BertMultiTaskTop/weibo_fake_ner/losses/0: 1.4930 - BertMultiTaskTop/weibo_fake_regression/losses/0: 1.2120 - BertMultiTaskTop/weibo_fake_vector_fit/losses/0: 0.3722 - BertMultiTaskTop/weibo_masklm/losses/0: 9.9305 - BertMultiTaskTop/weibo_premask_mlm/losses/0: 9.7947 - val_loss: 37.0011 - val_mean_acc: 0.2857 - val_fake_contrastive_learning_acc: 0.1429 - val_weibo_fake_cls_acc: 0.5714 - val_weibo_fake_ner_acc: 0.1429 - val_weibo_fake_regression_neg_mse: -1.0452 - val_weibo_fake_vector_fit_cos_sim: -0.3764 - val_BertMultiTaskTop/fake_contrastive_learning/simcse/losses/0: 13.1461 - val_BertMultiTaskTop/weibo_fake_cls/losses/0: 0.8110 - val_BertMultiTaskTop/weibo_fake_multi_cls/losses/0: 0.4187 - val_BertMultiTaskTop/weibo_fake_ner/losses/0: 1.5319 - val_BertMultiTaskTop/weibo_fake_regression/losses/0: 1.0452 - val_BertMultiTaskTop/weibo_fake_vector_fit/losses/0: 0.3764 - val_BertMultiTaskTop/weibo_masklm/losses/0: 9.9035 - val_BertMultiTaskTop/weibo_premask_mlm/losses/0: 9.7685
Epoch 2/2
1/1 [==============================] - 1s 977ms/step - mean_acc: 1.9844 - fake_contrastive_learning_acc: 0.2500 - weibo_fake_cls_acc: 0.6667 - weibo_fake_ner_acc: 0.2424 - weibo_fake_regression_neg_mse: -0.7024 - weibo_fake_vector_fit_cos_sim: -0.1600 - BertMultiTaskTop/fake_contrastive_learning/simcse/losses/0: 2.3416 - BertMultiTaskTop/weibo_fake_cls/losses/0: 0.6408 - BertMultiTaskTop/weibo_fake_multi_cls/losses/0: 0.4468 - BertMultiTaskTop/weibo_fake_ner/losses/0: 1.4879 - BertMultiTaskTop/weibo_fake_regression/losses/0: 0.7024 - BertMultiTaskTop/weibo_fake_vector_fit/losses/0: 0.1600 - BertMultiTaskTop/weibo_masklm/losses/0: 9.9203 - BertMultiTaskTop/weibo_premask_mlm/losses/0: 9.8009 - val_loss: 35.7190 - val_mean_acc: 0.2525 - val_fake_contrastive_learning_acc: 0.1667 - val_weibo_fake_cls_acc: 0.3750 - val_weibo_fake_ner_acc: 0.2159 - val_weibo_fake_regression_neg_mse: -1.0292 - val_weibo_fake_vector_fit_cos_sim: -0.3355 - val_BertMultiTaskTop/fake_contrastive_learning/simcse/losses/0: 11.9251 - val_BertMultiTaskTop/weibo_fake_cls/losses/0: 0.9174 - val_BertMultiTaskTop/weibo_fake_multi_cls/losses/0: 0.4063 - val_BertMultiTaskTop/weibo_fake_ner/losses/0: 1.4417 - val_BertMultiTaskTop/weibo_fake_regression/losses/0: 1.0292 - val_BertMultiTaskTop/weibo_fake_vector_fit/losses/0: 0.3355 - val_BertMultiTaskTop/weibo_masklm/losses/0: 9.9006 - val_BertMultiTaskTop/weibo_premask_mlm/losses/0: 9.7633
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">test_instance</span> <span class="o">=</span> <span class="n">LossCombinationStrategyBase</span><span class="p">(</span><span class="n">tb</span><span class="o">.</span><span class="n">params</span><span class="p">,</span> <span class="s1">&#39;test&#39;</span><span class="p">)</span>
<span class="c1"># validation losses</span>
<span class="n">test_instance</span><span class="o">.</span><span class="n">extract_loss_metric_dict_from_history</span><span class="p">(</span><span class="n">history</span><span class="o">=</span><span class="n">tb</span><span class="o">.</span><span class="n">all_model</span><span class="o">.</span><span class="n">history</span><span class="p">,</span> <span class="n">structure</span> <span class="o">=</span> <span class="n">create_dict_from_nested_model</span><span class="p">(</span><span class="n">tb</span><span class="o">.</span><span class="n">all_model</span><span class="p">))</span>
<span class="c1"># training losses</span>
<span class="n">test_instance</span><span class="o">.</span><span class="n">extract_loss_metric_dict_from_history</span><span class="p">(</span><span class="n">history</span><span class="o">=</span><span class="n">tb</span><span class="o">.</span><span class="n">all_model</span><span class="o">.</span><span class="n">history</span><span class="p">,</span> <span class="n">structure</span> <span class="o">=</span> <span class="n">create_dict_from_nested_model</span><span class="p">(</span><span class="n">tb</span><span class="o">.</span><span class="n">all_model</span><span class="p">),</span> <span class="n">prefix</span><span class="o">=</span><span class="s1">&#39;&#39;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>defaultdict(list,
            {&#39;BertMultiTaskTop&#39;: defaultdict(list,
                         {&#39;fake_contrastive_learning&#39;: defaultdict(list,
                                      {&#39;simcse&#39;: defaultdict(list,
                                                   {&#39;losses&#39;: [[2.494117498397827,
                                                      2.3415939807891846]]})}),
                          &#39;weibo_fake_cls&#39;: defaultdict(list,
                                      {&#39;losses&#39;: [[1.0908699035644531,
                                         0.6408037543296814]]}),
                          &#39;weibo_fake_multi_cls&#39;: defaultdict(list,
                                      {&#39;losses&#39;: [[0.4924350678920746,
                                         0.44675901532173157]]}),
                          &#39;weibo_fake_ner&#39;: defaultdict(list,
                                      {&#39;losses&#39;: [[1.4930245876312256,
                                         1.4878641366958618]]}),
                          &#39;weibo_fake_regression&#39;: defaultdict(list,
                                      {&#39;losses&#39;: [[1.211979866027832,
                                         0.7023975253105164]]}),
                          &#39;weibo_fake_vector_fit&#39;: defaultdict(list,
                                      {&#39;losses&#39;: [[0.3722432553768158,
                                         0.1600482314825058]]}),
                          &#39;weibo_masklm&#39;: defaultdict(list,
                                      {&#39;losses&#39;: [[9.930464744567871,
                                         9.920283317565918]]}),
                          &#39;weibo_premask_mlm&#39;: defaultdict(list,
                                      {&#39;losses&#39;: [[9.794666290283203,
                                         9.800870895385742]]})})})</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

</div>
 

